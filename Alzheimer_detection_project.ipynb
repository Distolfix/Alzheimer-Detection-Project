{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "ZCsYyrerwr_M",
        "outputId": "889cc73d-7a7a-4302-cd90-513a3d5f020a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYlWqrb12XR7"
      },
      "source": [
        "# **SUL DATASET**\n",
        "\n",
        "Il dataset è una versione pre-processata del dataset **OASIS Alzheimer's Detection** (un dataset di immagini MRI del cervello di 461 pazienti) utilizzato per rilevare i segni precoci dell’Alzheimer.\n",
        "\n",
        "Poiché le immagini MRI sono 3D, sono state divise lungo l'asse z (l'asse della profondità del cervello) in 175 fette e sono state selezionate le fette che vanno dalla 55 esima alla 124 esima al fine di ridurre il numero di immagini e concentrarsi sulle sezioni cerebrali rilevanti per l'analisi della demenza; Questo approccio ha generato immagini 2D per ogni paziente.\n",
        "\n",
        "Lo stesso approccio è stato utilizzato per le versioni delle MRI con segmentazione delle aree cerebrali offerte da OASIS effettuate tramite FSL FAST.\n",
        "\n",
        "****\n",
        "****\n",
        "\n",
        "Le immagini sono classificate in **quattro sottoclassi**, in base alla progressione della malattia:\n",
        "\n",
        "*   Moderate dementia (affetto da demenza)\n",
        "\n",
        "*   Very mild dementia (affetto da demenza molto lieve)\n",
        "* Mild dementia (affetto da demenza lieve)\n",
        "* Non-demented (non affetto da demenza)\n",
        "\n",
        "\n",
        "*La classificazione dei pazienti è stata effettuata sulla base delle valutazioni CDR (Clinical Dementia Rating), un punteggio che valuta la severità della demenza.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import zipfile\n",
        "import os\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import math\n",
        "import shutil\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0OeHZZn4m1jR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OPERAZIONI SUL DATASET**"
      ],
      "metadata": {
        "id": "Rw5x_fnyUQ8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operazioni preliminari"
      ],
      "metadata": {
        "id": "C9AERDTXVDwq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kuw_6Gfr0fAK"
      },
      "outputs": [],
      "source": [
        "# Estrazione dataset\n",
        "\n",
        "zip_path = \"/content/drive/My Drive/Alzheimer-detection-project/oasis 1.zip\"\n",
        "extract_folder = \"/content/Alzheimer-detection-project\"\n",
        "\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(\"File estratti:\", os.listdir(extract_folder))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R1jOwRUgt8q"
      },
      "outputs": [],
      "source": [
        "# Rimozione files inutili\n",
        "for dirpath, dirnames, filenames in os.walk(oasis1_path):\n",
        "    for filename in filenames:\n",
        "        if filename == \".DS_Store\":\n",
        "            file_path = os.path.join(dirpath, filename)\n",
        "            os.remove(file_path)\n",
        "            print(f\"Rimosso: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kXndm7p6nSb"
      },
      "outputs": [],
      "source": [
        "oasis1_path = os.path.join(extract_folder, \"oasis 1\")\n",
        "categories = ['Moderate Dementia', 'Mild Dementia', 'Very Mild Dementia', 'Non Demented']\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_segmented_path=os.path.join(category_path, 'mri segmented')\n",
        "    mri_path= os.path.join(category_path, 'mri scan')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VISUALIZZAZIONE GRAFICI** di distribuzione delle classi"
      ],
      "metadata": {
        "id": "EugS4zP8UZOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjW4NPYD0-J8"
      },
      "outputs": [],
      "source": [
        "# Numero di immagini per categoria - grafico di distribuzione delle classi\n",
        "\n",
        "somma=0\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_segmented_path=os.path.join(category_path, 'mri segmented')\n",
        "    for patient in os.listdir(mri_segmented_path):\n",
        "      images= os.listdir(os.path.join(mri_segmented_path, patient))\n",
        "      somma=somma+len(images)\n",
        "    somma=0\n",
        "\n",
        "valori=[]\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_path= os.path.join(category_path, 'mri scan')\n",
        "    for patient in os.listdir(mri_path):\n",
        "      images= os.listdir(os.path.join(mri_path, patient))\n",
        "      somma=somma+len(images)\n",
        "    print(f'numero foto {category}: {somma}')\n",
        "    valori.append(somma)\n",
        "    somma=0\n",
        "\n",
        "# Visualizzazione tramite istogramma\n",
        "plt.bar(categories, valori, color='skyblue')\n",
        "plt.title('Distribuzione delle classi', pad=20)\n",
        "plt.xlabel('Categorie')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Quantità foto')\n",
        "plt.show()\n",
        "print(f\" \")\n",
        "\n",
        "# Visualizzazione tramite grafico a torta\n",
        "plt.pie(valori, labels=categories, autopct='%1.1f%%', startangle=0)\n",
        "plt.title('Distribuzione delle classi',pad=20)\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **APPROCCI ALLO SBILANCIAMENTO DEL DATASET**"
      ],
      "metadata": {
        "id": "_Rfpv_EYWCyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il dataset è estremamente sbilanciato.\n",
        "\n",
        " **APPROCCI ADOTTATI PER AFFRONTARE IL PROBLEMA DELLO SBILANCIAMENTO**:\n",
        "\n",
        "- **Unione delle due classi minoritarie** (Mild Dementia e Moderate Demenntia) dato che il focus del progetto è una early detection dell'alzheimer.\n",
        "- **Downsampling parziale della classe maggioritaria** (Non Demented) per limitare il rischio di bias.\n",
        "- **Bilanciamento delle classi tramiti pesi** (class weights) durante la fase di addestramento per compensare le differenze residue."
      ],
      "metadata": {
        "id": "Z77KcrFELedh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sposto i files da Moderate dementia in Mild Dementia\n",
        "mod_d_path=os.path.join(oasis1_path, \"Moderate Dementia\")\n",
        "mild_d_path=os.path.join(oasis1_path, \"Mild Dementia\")\n",
        "source_path=os.path.join(mod_d_path, \"mri scan\")\n",
        "dest_path=os.path.join(mild_d_path, \"mri scan\")\n",
        "\n",
        "for folder in os.listdir(source_path):\n",
        "  source_file=os.path.join(source_path, folder)\n",
        "  shutil.move(source_file, dest_path)\n",
        "\n",
        "source_path=os.path.join(mod_d_path, \"mri segmented\")\n",
        "dest_path=os.path.join(mild_d_path, \"mri segmented\")\n",
        "for folder in os.listdir(source_path):\n",
        "  source_file=os.path.join(source_path, folder)\n",
        "  shutil.move(source_file, dest_path)\n"
      ],
      "metadata": {
        "id": "jwkmXH56MDW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rinomino la cartella\n",
        "mild_to_mod_path= os.path.join(oasis1_path, \"Mild to Moderate Dementia\")\n",
        "if os.path.exists(mild_d_path):\n",
        "    os.rename(mild_d_path, mild_to_mod_path)\n",
        "    print(\"Cartella rinominata con successo.\")\n",
        "else:\n",
        "    print(\"La cartella di origine non esiste.\")\n",
        "\n",
        "categories = ['Mild to Moderate Dementia', 'Very Mild Dementia', 'Non Demented']\n",
        "\n",
        "# Elimino la cartella vuota\n",
        "cartella_da_eliminare = os.path.join(oasis1_path, \"Moderate Dementia\")\n",
        "shutil.rmtree(cartella_da_eliminare)\n"
      ],
      "metadata": {
        "id": "byyBGxFmQxl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downsampling della classe maggioritaria\n",
        "nd_path=os.path.join(oasis1_path, \"Non Demented\")\n",
        "mri_path=os.path.join(nd_path, \"mri scan\")\n",
        "mri_seg_path=os.path.join(nd_path, \"mri segmented\")\n",
        "\n",
        "n=180\n",
        "folders=os.listdir(mri_path)\n",
        "to_delete=random.sample(folders, n)\n",
        "\n",
        "for folder in to_delete:\n",
        "  folder_seg= f\"{folder.strip()} seg\"\n",
        "  path=os.path.join(mri_path, folder)\n",
        "  path_seg=os.path.join(mri_seg_path, folder_seg)\n",
        "  shutil.rmtree(path)\n",
        "  shutil.rmtree(path_seg)"
      ],
      "metadata": {
        "id": "LSK5lQUWWYhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VISUALIZZAZIONE GRAFICI** di distribuzione delle classi in seguito a approcci per il bilanciamento"
      ],
      "metadata": {
        "id": "qPRfrEDMUuyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numero di immagini per categoria - grafico di distribuzione delle classi\n",
        "#dopo unione delle cartelle e downsampling\n",
        "\n",
        "somma=0\n",
        "\n",
        "valori=[]\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_path= os.path.join(category_path, 'mri scan')\n",
        "    for patient in os.listdir(mri_path):\n",
        "      images= os.listdir(os.path.join(mri_path, patient))\n",
        "      somma=somma+len(images)\n",
        "    print(f'numero foto {category}: {somma}')\n",
        "    valori.append(somma)\n",
        "    somma=0\n",
        "\n",
        "# Visualizzazione tramite istogramma\n",
        "plt.bar(categories, valori, color='skyblue')\n",
        "plt.title('Distribuzione delle classi', pad=20)\n",
        "plt.xlabel('Categorie')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Quantità foto')\n",
        "plt.show()\n",
        "print(f\" \")\n",
        "\n",
        "# Visualizzazione tramite grafico a torta\n",
        "plt.pie(valori, labels=categories, autopct='%1.1f%%', startangle=0)\n",
        "plt.title('Distribuzione delle classi',pad=20)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5G3uLjbiPEf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VISUALIZZAZIONE DI IMMAGINI A CAMPIONE** dal dataset"
      ],
      "metadata": {
        "id": "yYgJfDhoU6ty"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-HBnIBtL_pH"
      },
      "outputs": [],
      "source": [
        "#VISUALIZZAZIONE DI IMMAGINI A CAMPIONE\n",
        "\n",
        "# Scelta randomica della slice\n",
        "#folders=os.listdir(mri_path)\n",
        "#random_folder = random.choice(folders)\n",
        "#patient_path= os.path.join(mri_path, random_folder)\n",
        "#random_slice = random.choice(os.listdir(patient_path))\n",
        "\n",
        "# Stampa di un immagine segmentata e un immagine T1w per categoria\n",
        "for category in categories:\n",
        "  category_path = os.path.join(oasis1_path, category)\n",
        "  mri_segmented_path=os.path.join(category_path, 'mri segmented')\n",
        "  mri_path= os.path.join(category_path, 'mri scan')\n",
        "  folders=os.listdir(mri_path)\n",
        "  random_folder = random.choice(folders)\n",
        "  random_folder_seg= f\"{random_folder.strip()} seg\"\n",
        "\n",
        "  patient_path= os.path.join(mri_path, random_folder)\n",
        "  patient_path_seg= os.path.join(mri_segmented_path, random_folder_seg)\n",
        "\n",
        "  img_path = os.path.join(patient_path, 'slice_85.png')\n",
        "  img = mpimg.imread(img_path)\n",
        "  img_seg_path = os.path.join(patient_path_seg, 'slice_85.png')\n",
        "  img_seg = mpimg.imread(img_seg_path)\n",
        "\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "  axes[0].imshow(img)\n",
        "  axes[0].set_title(f\"Immagine T1w \\n-{category}-\")\n",
        "  axes[0].axis('off')\n",
        "\n",
        "  axes[1].imshow(img_seg)\n",
        "  axes[1].set_title(f\"Immagine segmentata \\n-{category}-\")\n",
        "  axes[1].axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Eic3f-oyMLE"
      },
      "outputs": [],
      "source": [
        "# Visualizzazione con etichette delle immagini segmentate\n",
        "\n",
        "# Scelta di un immagine segmentata (parte commentata per randomizzazione)\n",
        "\n",
        "#category='Very Mild Dementia'\n",
        "#category_path = os.path.join(oasis1_path, category)\n",
        "#mri_segmented_path = os.path.join(category_path, 'mri segmented')\n",
        "#folders = os.listdir(mri_segmented_path)\n",
        "#random_folder = random.choice(folders)\n",
        "#patient_path = os.path.join(mri_segmented_path, random_folder)\n",
        "#random_slice = random.choice(os.listdir(patient_path))\n",
        "#img_seg_path = os.path.join(patient_path, random_slice)\n",
        "\n",
        "img_seg = mpimg.imread(img_seg_path)\n",
        "img_seg = img_seg[:, :, 0]\n",
        "\n",
        "labels=['Background', 'CSF', 'Materia grigia', 'Materia bianca']\n",
        "valori_unici = np.unique(img_seg)\n",
        "print(f\"{len(valori_unici)} valori differenti: {valori_unici}\\n\\n\")\n",
        "\n",
        "# creazione della leggenda e visualizzazione\n",
        "cmap = plt.cm.Set1_r\n",
        "fig, ax = plt.subplots(figsize=(7, 7))\n",
        "ax.imshow(img_seg, cmap=cmap)\n",
        "\n",
        "patches = []\n",
        "for i, val in enumerate(valori_unici):\n",
        "  patch = mpatches.Patch(color=cmap(val), label=labels[i])\n",
        "  patches.append(patch)\n",
        "ax.legend(handles=patches, loc='upper right')\n",
        "\n",
        "ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I valori dell'output segmentato sono normalizzati e lo standard è:\n",
        "\n",
        "| Valore         | Etichetta         |  \n",
        "|----------------|-------------------|\n",
        "| `0.0`          | **Background**     |\n",
        "| `0.33333334`   | **CSF**            |\n",
        "| `0.6666667`    | **Materia Grigia** |\n",
        "| `1.0`          | **Materia Bianca** |"
      ],
      "metadata": {
        "id": "W8YlrSJThzEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OPERAZIONI SU DIMENSIONI E CANALI** delle immagini"
      ],
      "metadata": {
        "id": "ssHjpwQzVR4Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amoK9wFYDQEM"
      },
      "outputs": [],
      "source": [
        "# Check dimensioni e canali\n",
        "\n",
        "images_dimentions=set()\n",
        "images_channels=set()\n",
        "\n",
        "# Per ognni immagine in ogni categoria salva dimensioni e numero di canale negli insiemi\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_path= os.path.join(category_path, 'mri scan')\n",
        "    for patient in os.listdir(mri_path):\n",
        "      patient_path=os.path.join(mri_path, patient)\n",
        "      file_path=os.path.join(patient_path, '.DS_Store')\n",
        "      if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "      images= os.listdir(os.path.join(mri_path, patient))\n",
        "\n",
        "      for image in images:\n",
        "        image_path=os.path.join(patient_path, image)\n",
        "        i = mpimg.imread(image_path)\n",
        "        w, h = i.shape[:2]\n",
        "        images_dimentions.add((w, h))\n",
        "\n",
        "        if len(i.shape) == 3:\n",
        "          channels = i.shape[2]\n",
        "        else:\n",
        "          channels = 1\n",
        "        images_channels.add(channels)\n",
        "\n",
        "# Controllo del numero di elementi negli insiemi\n",
        "if len(images_dimentions) == 1:\n",
        "  print(\"tutte le immagini hanno le stesse dimensioni\", images_dimentions.pop())\n",
        "else:\n",
        "  print(\"NON tutte le immagini hanno le stesse dimensioni:\")\n",
        "  for dim in images_dimentions:\n",
        "        print(\" \", dim)\n",
        "\n",
        "if len(images_channels) == 1:\n",
        "    print(\"tutte le immagini hanno lo stesso numero di canali:\", images_channels.pop())\n",
        "else:\n",
        "    print(\"NON tutte le immagini hanno lo stesso numero di canali:\")\n",
        "    for ch in images_channels:\n",
        "        print(\" \", ch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBa11H_kuOwD"
      },
      "outputs": [],
      "source": [
        "# Conversione delle immagini MRI in scale di grigi\n",
        "# Utilizzo Grayscale = 0.299 * R + 0.587 * G + 0.114 * B\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_path= os.path.join(category_path, 'mri scan')\n",
        "    for patient in os.listdir(mri_path):\n",
        "        patient_path = os.path.join(mri_path, patient)\n",
        "        file_path = os.path.join(patient_path, '.DS_Store')\n",
        "        if os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "        images = os.listdir(os.path.join(mri_path, patient))\n",
        "\n",
        "        for image in images:\n",
        "            image_path = os.path.join(patient_path, image)\n",
        "            i = mpimg.imread(image_path)\n",
        "\n",
        "            if len(i.shape) == 3 and i.shape[2] >= 3:\n",
        "                i_rgb = i[..., :3]\n",
        "\n",
        "                i_gray = 0.299 * i_rgb[..., 0] + 0.587 * i_rgb[..., 1] + 0.114 * i_rgb[..., 2]\n",
        "                i_gray = (i_gray * 255).astype(np.uint8)\n",
        "                gray_img = Image.fromarray(i_gray)\n",
        "                gray_img.save(image_path)\n",
        "\n",
        "# Check del nuovo numero di canali\n",
        "images_channels=set()\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_path= os.path.join(category_path, 'mri scan')\n",
        "    for patient in os.listdir(mri_path):\n",
        "      patient_path=os.path.join(mri_path, patient)\n",
        "      images= os.listdir(os.path.join(mri_path, patient))\n",
        "\n",
        "      for image in images:\n",
        "        image_path=os.path.join(patient_path, image)\n",
        "        i = mpimg.imread(image_path)\n",
        "\n",
        "        if len(i.shape) == 3:\n",
        "          channels = i.shape[2]\n",
        "        else:\n",
        "          channels = 1\n",
        "        images_channels.add(channels)\n",
        "\n",
        "if len(images_channels) == 1:\n",
        "    print(\"tutte le immagini hanno lo stesso numero di canali:\", images_channels.pop())\n",
        "else:\n",
        "    print(\"NON tutte le immagini hanno lo stesso numero di canali:\")\n",
        "    for ch in images_channels:\n",
        "        print(\" \", ch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DEVIAZIONE STANDARD E MSE**"
      ],
      "metadata": {
        "id": "qARsq0e1VY2G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leOGYBBFGWgw"
      },
      "source": [
        " **DEVIAZIONE STANDARD --> misura dove variano di più i pixel**\n",
        "\n",
        "- STD ALTA: molta variabilità nei valori dei pixel\n",
        "\n",
        "- STD BASSA: poca variabilità nei valori dei pixel\n",
        "\n",
        "**MEAN SQUARE ERROR --> misura quanto ogni pixel si allontana dalla media**\n",
        "\n",
        "- MSE ALTO: alta variabilità intra-classe\n",
        "\n",
        "- MSE BASSO: bassa variabilità intra-classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTh4PY-pyG50"
      },
      "outputs": [],
      "source": [
        "# Calcolo della deviazione standard e mse\n",
        "\n",
        "std_interclasse= {}\n",
        "mse_interclasse={}\n",
        "std_intraclasse={}\n",
        "mse_intraclasse={}\n",
        "\n",
        "\n",
        "selected_slices = ['slice_60.png', 'slice_85.png', 'slice_103.png', 'slice_120.png']  # Esempio: nomi delle slice\n",
        "\n",
        "for name in selected_slices:  #for name in images per prendere tutte le immagini\n",
        "  slices_all_categories = []\n",
        "  for category in categories:\n",
        "    slices = []\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_path= os.path.join(category_path, 'mri scan')\n",
        "    for patient in os.listdir(mri_path):\n",
        "      patient_path=os.path.join(mri_path, patient)\n",
        "      slice_of_interest= os.path.join(patient_path, name)\n",
        "      i = Image.open(slice_of_interest)\n",
        "      i_array = np.array(i)\n",
        "      slices.append(i_array)\n",
        "\n",
        "    if slices:\n",
        "        slices_stack_interclasse = np.stack(slices)\n",
        "        std_map_interclasse = np.std(slices_stack_interclasse, axis=0)\n",
        "        mean_slice_interclasse = np.mean(slices_stack_interclasse, axis=0)\n",
        "        mse_map_interclasse = np.mean((slices_stack_interclasse - mean_slice_interclasse) ** 2, axis=0)\n",
        "        mse_interclasse[(name,category)] = mse_map_interclasse\n",
        "        std_interclasse[(name, category)] = std_map_interclasse\n",
        "\n",
        "        slices_all_categories.extend(slices)\n",
        "\n",
        "  if slices_all_categories:\n",
        "        slices_stack_intraclasse = np.stack(slices_all_categories)\n",
        "        std_map_intraclasse = np.std(slices_stack_intraclasse, axis=0)\n",
        "        mean_slice_intraclasse = np.mean(slices_stack_intraclasse, axis=0)\n",
        "        mse_map_intraclasse = np.mean((slices_stack_intraclasse - mean_slice_intraclasse) ** 2, axis=0)\n",
        "        std_intraclasse[name] = std_map_intraclasse\n",
        "        mse_intraclasse[name] = mse_map_intraclasse\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmVfwzL6Yh7b"
      },
      "outputs": [],
      "source": [
        "#  Visualizzazione della deviazione standard (sulla stessa slice) intra classe\n",
        "\n",
        "columns = 3\n",
        "imgs = len(std_interclasse)\n",
        "rows = math.ceil(imgs / columns)\n",
        "plt.figure(figsize=(columns * 3, rows * 3))\n",
        "\n",
        "for idx, ((name, category), std_map_interclasse) in enumerate((std_interclasse.items())):\n",
        "    plt.subplot(rows, columns, idx + 1)\n",
        "    im = plt.imshow(std_map_interclasse, cmap='hot')\n",
        "    plt.title(f\"STD - {category}\\n{name}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.colorbar(im, ax=plt.gcf().get_axes(), fraction=0.02, pad=0.04)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizzazione della deviazione standard (sulla stessa slice) inter classe\n",
        "\n",
        "columns = 4\n",
        "imgs = len(std_intraclasse)\n",
        "rows = math.ceil(imgs / columns)\n",
        "plt.figure(figsize=(columns * 3, rows * 3))\n",
        "\n",
        "for idx, (name, std_map_intraclasse) in enumerate(std_intraclasse.items()):\n",
        "    plt.subplot(rows, columns, idx + 1)\n",
        "    im = plt.imshow(std_map_intraclasse, cmap='hot')\n",
        "    plt.title(f\"STD - {name}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.colorbar(im, ax=plt.gcf().get_axes(), fraction=0.02, pad=0.04)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zWLEjshnCoyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizzazione dell'MSE (sulla stessa slice) intra classe\n",
        "\n",
        "columns = 3\n",
        "imgs = len(mse_interclasse)\n",
        "rows = math.ceil(imgs / columns)\n",
        "plt.figure(figsize=(columns * 3, rows * 3))\n",
        "\n",
        "for idx, ((name, category), mse_map_interclasse) in enumerate(mse_interclasse.items()):\n",
        "    plt.subplot(rows, columns, idx + 1)\n",
        "    im = plt.imshow(mse_map_interclasse, cmap='hot')\n",
        "    plt.title(f\"MSE - {category}\\n{name}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.colorbar(im, ax=plt.gcf().get_axes(), fraction=0.02, pad=0.04)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b--XknwS5rzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoDtph4RBcGE"
      },
      "outputs": [],
      "source": [
        "# Visualizzazione dell'MSE (sulla stessa slice) inter classe\n",
        "\n",
        "columns = 4\n",
        "imgs = len(mse_intraclasse)\n",
        "rows = math.ceil(imgs / columns)\n",
        "plt.figure(figsize=(columns * 3, rows * 3))\n",
        "\n",
        "for idx, (name, mse_map_intraclasse) in enumerate(mse_intraclasse.items()):\n",
        "    plt.subplot(rows, columns, idx + 1)\n",
        "    im = plt.imshow(mse_map_intraclasse, cmap='hot')\n",
        "    plt.title(f\"MSE - {name}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.colorbar(im, ax=plt.gcf().get_axes(), fraction=0.02, pad=0.04)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DIVISIONE IN TRAINING SET E TEST SET**"
      ],
      "metadata": {
        "id": "UbCis-nkVnkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisione in training e test set\n",
        "\n",
        "labeled_patients=[]\n",
        "segmented_patients=[]\n",
        "\n",
        "for cat in categories:\n",
        "  category_path = os.path.join(oasis1_path, cat)\n",
        "  mri_path= os.path.join(category_path, 'mri scan')\n",
        "  mri_segmented_path=os.path.join(category_path, 'mri segmented')\n",
        "  for patient in os.listdir(mri_path):\n",
        "    patient_seg= f\"{patient.strip()} seg\"\n",
        "    patient_path=os.path.join(mri_path, patient)\n",
        "    patient_seg_path=os.path.join(mri_segmented_path, patient_seg)\n",
        "    labeled_patients.append((cat, patient))\n",
        "    segmented_patients.append((cat, patient_seg))\n",
        "\n",
        "df=pd.DataFrame(labeled_patients, columns=[\"label\", \"patient_id\"])\n",
        "df_seg=pd.DataFrame(segmented_patients, columns=[\"label\", \"patient_id\"])\n"
      ],
      "metadata": {
        "id": "14mDJQjR3A2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x, test_x = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "train_ids = train_x['patient_id'].tolist()\n",
        "test_ids = test_x['patient_id'].tolist()\n",
        "\n",
        "train_y = df_seg[df_seg['patient_id'].isin([f\"{pid} seg\" for pid in train_ids])]\n",
        "test_y = df_seg[df_seg['patient_id'].isin([f\"{pid} seg\" for pid in test_ids])]\n",
        "\n",
        "print(\"Numero di pazienti segmentati in train_y:\", len(train_y))\n",
        "print(\"Numero di pazienti in train_x:\", len(train_x))\n",
        "print(\"Numero di pazienti segmentati in test_y:\", len(test_y))\n",
        "print(\"Numero di pazienti in test_x:\", len(test_x))\n"
      ],
      "metadata": {
        "id": "Z6BYP1-IQ3Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CONVERSIONE IMMAGINI SEGMENTATE IN MAPPE DI CLASSI**"
      ],
      "metadata": {
        "id": "X5gybPbdVyLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione per la conversione di immagine segmentata in una mappa di classi intere\n",
        "value_to_class = {\n",
        "    0.0: 0,\n",
        "    1/3: 1,\n",
        "    2/3: 2,\n",
        "    1.0: 3\n",
        "}\n",
        "\n",
        "def class_map(img, d):\n",
        "  class_map = np.zeros_like(img, dtype=np.uint8)\n",
        "  for val, class_id in d.items():\n",
        "    mask = np.isclose(img, val)\n",
        "    class_map[mask] = class_id\n",
        "  return class_map"
      ],
      "metadata": {
        "id": "LgldeL2d7zM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversione delle immagini segmentate in mappe\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_segmented_path=os.path.join(category_path, 'mri segmented')\n",
        "    for patient in os.listdir(mri_segmented_path):\n",
        "      patient_path= os.path.join(mri_segmented_path, patient)\n",
        "      for filename in os.listdir(patient_path):\n",
        "        img_path = os.path.join(patient_path, filename)\n",
        "        img_seg = mpimg.imread(img_seg_path)\n",
        "        img_seg = img_seg[:, :, 0]\n",
        "        classmap = class_map(img_seg, value_to_class)\n",
        "        save_path = os.path.join(patient_path, filename.replace(\".png\", \".npy\"))\n",
        "        np.save(save_path, classmap)"
      ],
      "metadata": {
        "id": "bdVh66QVUjcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SBILANCIAMENTO TRA CLASSI DELLA SEGMENTAZIONE**"
      ],
      "metadata": {
        "id": "a35-Kx8hW5nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcolo del numero di pixel per ogni classe per vedere se sono presenti sbilanciamenti\n",
        "\n",
        "labels = ['Background', 'CSF', 'Materia grigia', 'Materia bianca']\n",
        "total_counts = np.zeros(4, dtype=np.int64)\n",
        "image_count = 0\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(oasis1_path, category)\n",
        "    mri_segmented_path=os.path.join(category_path, 'mri segmented')\n",
        "    for patient in os.listdir(mri_segmented_path):\n",
        "      patient_path= os.path.join(mri_segmented_path, patient)\n",
        "      for filename in os.listdir(patient_path):\n",
        "        if not filename.endswith('.npy'):\n",
        "          continue\n",
        "        file_path = os.path.join(patient_path, filename)\n",
        "        class_map = np.load(file_path)\n",
        "        pixel_counts = np.bincount(class_map.flatten(), minlength=4)\n",
        "        total_counts += pixel_counts\n",
        "        image_count += 1\n",
        "avg_counts = total_counts / image_count\n",
        "\n",
        "\n",
        "# Visualizzazione tramite istogramma\n",
        "plt.bar(labels, total_counts)\n",
        "plt.xlabel('Classi')\n",
        "plt.ylabel('Numero di Pixel')\n",
        "plt.title('Distribuzione dei Pixel per Classe')\n",
        "plt.show()\n",
        "\n",
        "# Visualizzazione tramite grafico a torta\n",
        "plt.pie(total_counts, labels=labels, autopct='%1.1f%%', startangle=0)\n",
        "plt.title('Distribuzione dei pixel per classe',pad=20)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rb75F2rGf9fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcolo dei pesi per la loss function\n",
        "\n",
        "pixels = avg_counts.sum()\n",
        "class_weights = pixels / (4 * avg_counts)\n",
        "\n",
        "for class_id, weight in enumerate(class_weights):\n",
        "    print(f\"Classe {labels[class_id]}: Peso = {weight:.4f}\")"
      ],
      "metadata": {
        "id": "TlZsSqYAl_pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DEFINIZIONE DELLA U NET** per la segmentazione"
      ],
      "metadata": {
        "id": "rkfOqPGnQP44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Funzioni ausiliarie al forward pass*"
      ],
      "metadata": {
        "id": "k9lK11X2SRE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Funzioni di pooling e upsampling**"
      ],
      "metadata": {
        "id": "nfrSfH4qTnzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Max pooling\n",
        "\n",
        "def max_pooling(img, pool_size=2, stride=2):\n",
        "  if img.ndim == 3:\n",
        "    img = img[:, :, :, np.newaxis]\n",
        "  batch_size, img_height, img_width, img_channels = img.shape\n",
        "  pool_height, pool_width = (pool_size, pool_size)\n",
        "  output_height = (img_height - pool_height) // stride + 1\n",
        "  output_width = (img_width - pool_width) // stride + 1\n",
        "  output = np.zeros((batch_size, output_height, output_width, img_channels))\n",
        "  for b in range(batch_size):\n",
        "    for i in range(output_height):\n",
        "      for j in range(output_width):\n",
        "        row=i*stride\n",
        "        column=j*stride\n",
        "        for c in range(img_channels):\n",
        "          window = img[b, row:row + pool_height, column:column + pool_width, c]\n",
        "          output[b,i, j, c] = np.max(window)\n",
        "  return output"
      ],
      "metadata": {
        "id": "seuN81iwsanV"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsampling\n",
        "\n",
        "def upsample(img, scale=2):\n",
        "  if img.ndim == 3:  # (B, H, W)\n",
        "    img = img[:, :, :, np.newaxis]\n",
        "  batch_size, img_height, img_width, img_channels = img.shape\n",
        "  output_height=img_height*scale\n",
        "  output_width=img_width*scale\n",
        "  output = np.zeros((batch_size, output_height, output_width, img_channels))\n",
        "  for b in range(batch_size):\n",
        "    for row in range(img_height):\n",
        "      for column in range(img_width):\n",
        "        for i in range(scale):\n",
        "          for j in range(scale):\n",
        "            for c in range(img_channels):\n",
        "              output[b, row * scale + i, column * scale + j, c] = img[b,row, column,c]\n",
        "  return output"
      ],
      "metadata": {
        "id": "rvVVvHgQ3XoK"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Funzione di perdita** (loss function)"
      ],
      "metadata": {
        "id": "IJdwUQMdTYvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function e funzioni ausiliarie\n",
        "\n",
        "def onehot_encoding(targets, n_classes):\n",
        "  identity = np.eye(n_classes)\n",
        "  output = identity[targets]\n",
        "\n",
        "\n",
        "  return output\n",
        "\n",
        "\n",
        "\n",
        "def weighted_cross_entropy_loss(targets, predictions, class_weights):\n",
        "  epsilon = 1e-10\n",
        "  log_predictions = np.log(predictions + epsilon)\n",
        "\n",
        "  one_hot_targets = onehot_encoding(targets, n_classes)\n",
        "  cross_entropy = -np.sum(one_hot_targets * log_predictions, axis=-1)\n",
        "  weighted_cross_entropy = cross_entropy * class_weights[targets]\n",
        "  loss_per_batch = np.sum(weighted_cross_entropy, axis=(1, 2))\n",
        "  loss = np.mean(loss_per_batch)\n",
        "\n",
        "  return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "y4TCrsJYt-7R"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Funzioni di attivazione**"
      ],
      "metadata": {
        "id": "fKxsDCiUR2xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU\n",
        "\n",
        "def ReLU(img):\n",
        "  return np.maximum(0, img)"
      ],
      "metadata": {
        "id": "IgY40UtLRjCo"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax - per rendere l'output in probabilità per classe\n",
        "\n",
        "def softmax(predictions):\n",
        "  if predictions.ndim != 4:\n",
        "    raise ValueError(f\"Expected predictions of shape (B, H, W, C), got {predictions.shape}\")\n",
        "  exp_preds = np.exp(predictions - np.max(predictions, axis=1, keepdims=True))\n",
        "  sum_exp_preds = np.sum(exp_preds, axis=1, keepdims=True)\n",
        "  softmax_output = exp_preds / sum_exp_preds\n",
        "  return softmax_output"
      ],
      "metadata": {
        "id": "2pR4eyNQ4XHe"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Funzioni di ottimizzazione**"
      ],
      "metadata": {
        "id": "jcWaaQ-ET7Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Funzioni per il forward pass*"
      ],
      "metadata": {
        "id": "FMqUwh4sQ3tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convoluzione\n",
        "\n",
        "def convolve(imgs, kernel):\n",
        "  if imgs.ndim == 3:\n",
        "    imgs = imgs[:, :, :, np.newaxis]\n",
        "\n",
        "  batch_size, img_height, img_width, imgs_channels = imgs.shape\n",
        "  ker_height, ker_width = kernel.shape\n",
        "\n",
        "  pad_h = ker_height // 2\n",
        "  pad_w = ker_width // 2\n",
        "  padded_imgs = np.pad(imgs, pad_width=((0, 0), (pad_h, pad_h), (pad_w, pad_w), (0, 0)),\n",
        "        mode='constant',constant_values=0)\n",
        "\n",
        "  output = np.zeros((batch_size, img_height, img_width, imgs_channels))\n",
        "  for i in range(batch_size):\n",
        "    img = padded_imgs[i]\n",
        "    for row in range(img_height):\n",
        "      for column in range(img_width):\n",
        "        for c in range(imgs_channels):\n",
        "          window = img[row:row + ker_height, column:column + ker_width,c]\n",
        "          output[i, row, column, c]=np.sum(window * kernel)\n",
        "  return output"
      ],
      "metadata": {
        "id": "S1e6a8nljw42"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convoluzione finale\n",
        "\n",
        "def final_convolve_1x1(imgs, filters):\n",
        "  img_batch, img_height, img_width, img_channels = imgs.shape\n",
        "  _, _, _, filters_channels = filters.shape\n",
        "\n",
        "  output = np.zeros((img_batch, img_height, img_width, filters_channels))\n",
        "  for b in range(img_batch):\n",
        "    for h in range(img_height):\n",
        "      for w in range(img_width):\n",
        "        for oc in range(filters_channels):\n",
        "          for ic in range(img_channels):\n",
        "            output[b, h, w, oc] += imgs[b, h, w, ic] * filters[0, 0, ic, oc]\n",
        "  return output"
      ],
      "metadata": {
        "id": "oy72mnT0h7X6"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione per la concatenazione\n",
        "\n",
        "def concatenate(img_contr, img_exp):\n",
        "  if img_contr.ndim == 3:\n",
        "    img_contr = img_contr[:, :, :, np.newaxis]\n",
        "  if img_exp.ndim == 3:\n",
        "        img_exp = img_exp[:, :, :, np.newaxis]\n",
        "  batch_size, contr_height, contr_width , _= img_contr.shape\n",
        "  _, exp_height, exp_width, _ = img_exp.shape\n",
        "  if contr_height == exp_height and contr_width == exp_width:\n",
        "    concatenated = np.concatenate((img_contr, img_exp), axis=3)\n",
        "    return concatenated"
      ],
      "metadata": {
        "id": "McIllkV8hn_T"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "\n",
        "def encoder(imgs, filters):\n",
        "  blocks=[]\n",
        "  saved_enc = {}\n",
        "  saved_enc[\"input_convolve\"] = imgs\n",
        "\n",
        "  c=convolve(imgs, filters[0])\n",
        "  saved_enc[\"conv0\"] = c\n",
        "  c=ReLU(c)\n",
        "  blocks.append(c)\n",
        "\n",
        "  c=convolve(c, filters[1])\n",
        "  saved_enc[\"conv1\"] = c\n",
        "  c=ReLU(c)\n",
        "  blocks.append(c)\n",
        "\n",
        "  c=max_pooling(c)\n",
        "\n",
        "  return c, blocks, saved_enc"
      ],
      "metadata": {
        "id": "M5xdEN0Z5Y4W"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "\n",
        "def decoder(imgs, blocks, filters):\n",
        "  saved = {}\n",
        "\n",
        "  saved[\"input_upsample\"] = imgs\n",
        "  c = upsample(imgs)\n",
        "  saved[\"upsampled\"] = c\n",
        "\n",
        "  skip = blocks.pop()\n",
        "  saved[\"skip\"] = skip\n",
        "\n",
        "  c = concatenate(c, skip)\n",
        "  saved[\"concatenated\"] = c\n",
        "\n",
        "  c = convolve(c, filters[0])\n",
        "  saved[\"conv0\"] = c\n",
        "  c = ReLU(c)\n",
        "\n",
        "  saved[\"input_conv1\"] = c\n",
        "  c = convolve(c, filters[1])\n",
        "  saved[\"conv1\"] = c\n",
        "  c = ReLU(c)\n",
        "\n",
        "  return c, saved\n"
      ],
      "metadata": {
        "id": "74MnQDuvO5G7"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bottleneck\n",
        "\n",
        "def bottleneck(imgs, filters):\n",
        "  saved_b = {}\n",
        "\n",
        "  saved_b[\"input_convolve0\"] = imgs\n",
        "  c=convolve(imgs, filters[0])\n",
        "  saved_b[\"convolved0\"] = c\n",
        "  c=ReLU(c)\n",
        "\n",
        "  saved_b[\"input_convolve1\"] = c\n",
        "  c=convolve(c, filters[1])\n",
        "  saved_b[\"convolved1\"] = c\n",
        "  c=ReLU(c)\n",
        "\n",
        "  return c , saved_b"
      ],
      "metadata": {
        "id": "WQhjOPYCPbGF"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Funzioni ausiliarie al backward pass*"
      ],
      "metadata": {
        "id": "m-wYt4Wzldl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Funzioni di pooling e upsampling**"
      ],
      "metadata": {
        "id": "OwwytHfHCMcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivata del max pooling\n",
        "\n",
        "def max_pooling_backward(dout, input, pool_size, stride):\n",
        "\n",
        "  batch_size, height, width, channels = input.shape\n",
        "  out_height, out_width = dout.shape[1], dout.shape[2]\n",
        "\n",
        "  output = np.zeros_like(input)\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    for h in range(out_height):\n",
        "      for w in range(out_width):\n",
        "        for c in range(channels):\n",
        "          h_start = h * stride\n",
        "          h_end = h_start + pool_size\n",
        "          w_start = w * stride\n",
        "          w_end = w_start + pool_size\n",
        "\n",
        "          window = input[i, h_start:h_end, w_start:w_end, c]\n",
        "          max_pos = np.unravel_index(np.argmax(window), window.shape)\n",
        "\n",
        "          output[i, h_start + max_pos[0], w_start + max_pos[1], c] += dout[i, h, w, c]\n",
        "\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "PAPHXOBetDG6"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivata dell'upsampling\n",
        "\n",
        "def upsample_backward(dout, img, scale=2):\n",
        "  if img.ndim == 3:\n",
        "      img = img[:, :, :, np.newaxis]\n",
        "  batch_size, output_height, output_width, img_channels = dout.shape\n",
        "\n",
        "  img_height = output_height // scale\n",
        "  img_width = output_width // scale\n",
        "\n",
        "  # Creiamo una variabile di output per accumulare i gradienti\n",
        "  dinput = np.zeros_like(img)\n",
        "\n",
        "  for b in range(batch_size):\n",
        "    for row in range(img_height):\n",
        "      for column in range(img_width):\n",
        "        for i in range(scale):\n",
        "          for j in range(scale):\n",
        "            for c in range(img_channels):\n",
        "              dinput[b, row, column, c] += dout[b, row * scale + i, column * scale + j, c]\n",
        "\n",
        "  return dinput\n"
      ],
      "metadata": {
        "id": "jIEJDAE_FAo4"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Funzioni di attivazione**"
      ],
      "metadata": {
        "id": "HwG_DvRzB47D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivata della ReLU\n",
        "\n",
        "def ReLU_backward(grad, input):\n",
        "  return grad * (input > 0)"
      ],
      "metadata": {
        "id": "7-gqpxploYZm"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Funzioni di perdita** (loss function)"
      ],
      "metadata": {
        "id": "VKDMrf_kB_rG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradiente della funzione di loss\n",
        "def grad(targets, predictions, class_weights):\n",
        "  one_hot_targets = onehot_encoding(targets, predictions.shape[-1])\n",
        "  weights = class_weights[targets]\n",
        "  weights = weights[..., np.newaxis]\n",
        "  grad = - (one_hot_targets * weights) / (predictions + 1e-8)\n",
        "  grad /= np.prod(targets.shape)\n",
        "  return grad"
      ],
      "metadata": {
        "id": "R3xSQeloooPE"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Funzioni per il backward pass*"
      ],
      "metadata": {
        "id": "HhLdmFhOBvEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivata della convoluzione\n",
        "\n",
        "def convolve_backward(dout, input, kernel):\n",
        "  if input.ndim == 3:\n",
        "    input = input[:, :, :, np.newaxis]\n",
        "  if dout.ndim == 3:\n",
        "    dout = dout[:, :, :, np.newaxis]\n",
        "\n",
        "  batch_size, img_height, img_width, channels = input.shape\n",
        "  ker_heigt, ker_width = kernel.shape\n",
        "\n",
        "  pad_h = ker_heigt // 2\n",
        "  pad_w = ker_width // 2\n",
        "\n",
        "  padded_input = np.pad(input, ((0, 0), (pad_h, pad_h), (pad_w, pad_w), (0, 0)), mode='constant')\n",
        "  dinput = np.zeros_like(padded_input, dtype=np.float64)\n",
        "  dkernel = np.zeros_like(kernel, dtype=np.float64)\n",
        "\n",
        "  for b in range(batch_size):\n",
        "    for h in range(img_height):\n",
        "      for w in range(img_width):\n",
        "        for c in range(channels):\n",
        "          window = padded_input[b, h:h + ker_heigt, w:w + ker_width, c]\n",
        "          dkernel += window * dout[b, h, w, c]\n",
        "          dinput[b, h:h + ker_heigt, w:w + ker_width, c] += kernel * dout[b, h, w, c]\n",
        "\n",
        "  dinput = dinput[:, pad_h:pad_h + img_height, pad_w:pad_w + img_width, :]\n",
        "  return dinput, dkernel\n",
        "\n"
      ],
      "metadata": {
        "id": "yaAvscV9pmLu"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivata della convoluzione finale\n",
        "\n",
        "def final_convolve_1x1_backward(dout, imgs, filters):\n",
        "  img_batch, img_height, img_width, img_channels = imgs.shape\n",
        "  _, _, _, filters_channels = filters.shape\n",
        "\n",
        "  dimgs = np.zeros_like(imgs)\n",
        "  dfilters = np.zeros_like(filters)\n",
        "\n",
        "  for b in range(img_batch):\n",
        "    for h in range(img_height):\n",
        "      for w in range(img_width):\n",
        "        for oc in range(filters_channels):\n",
        "          for ic in range(img_channels):\n",
        "            dimgs[b, h, w, ic] += dout[b, h, w, oc] * filters[0, 0, ic, oc]\n",
        "            dfilters[0, 0, ic, oc] += imgs[b, h, w, ic] * dout[b, h, w, oc]\n",
        "\n",
        "    return dimgs, dfilters\n",
        "\n"
      ],
      "metadata": {
        "id": "1SOxkr46Yptc"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivata della concatenazione\n",
        "\n",
        "def concatenate_backward(dout, img_contr, img_exp):\n",
        "  c1 = img_contr.shape[-1]\n",
        "  c2 = img_exp.shape[-1]\n",
        "  dimg_contr = dout[..., :c1]\n",
        "  dimg_exp = dout[..., c1:c1 + c2]\n",
        "  return dimg_contr, dimg_exp\n"
      ],
      "metadata": {
        "id": "oJv8R_t2-rFP"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder backward\n",
        "\n",
        "def encoder_backward(dout, blocks, filters, saved_enc):\n",
        "  grads = [None, None]\n",
        "\n",
        "  dmaxpool = max_pooling_backward(dout, blocks.pop(), pool_size=2, stride=2)\n",
        "\n",
        "  dout = ReLU_backward(dmaxpool, saved_enc[\"conv1\"])\n",
        "  dconv1, grads[1] = convolve_backward(dout, blocks.pop(), filters[1])\n",
        "\n",
        "  dout = ReLU_backward(dconv1, saved_enc[\"conv0\"])\n",
        "  dconv2, grads[0] = convolve_backward(dout, saved_enc[\"input_convolve\"], filters[0])\n",
        "\n",
        "  return dconv2, grads\n"
      ],
      "metadata": {
        "id": "_WU2HvbmDl5d"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder backwards\n",
        "\n",
        "def decoder_backward(dout, saved, filters):\n",
        "  grads = [None, None]\n",
        "\n",
        "  drelu2 = ReLU_backward(dout, saved[\"conv1\"])\n",
        "\n",
        "  dconv2, grads[1] = convolve_backward(drelu2, saved[\"input_conv1\"], filters[1])\n",
        "\n",
        "  drelu1 = ReLU_backward(dconv2, saved[\"conv0\"])\n",
        "\n",
        "  dconv1, grads[0] = convolve_backward(drelu1, saved[\"concatenated\"], filters[0])\n",
        "\n",
        "  dupsampled, dskip = concatenate_backward(dconv1, [saved[\"upsampled\"], saved[\"skip\"]])\n",
        "\n",
        "  dinput = upsample_backward(dupsampled, saved[\"input_upsample\"])\n",
        "\n",
        "  return dinput, dskip, grads\n"
      ],
      "metadata": {
        "id": "vnbSxsq4CvVg"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bottleneck backwards\n",
        "\n",
        "def decoder_backward(dout, saved, filters):\n",
        "  grads = [None, None]\n",
        "\n",
        "  drelu2 = ReLU_backward(dout, saved[\"convolved1\"])\n",
        "  dconv2, grads[1] = convolve_backward(drelu2, saved[\"input_convolve1\"], filters[1])\n",
        "\n",
        "  drelu1 = ReLU_backward(dout, saved[\"convolved0\"])\n",
        "  dconv1, grads[0] = convolve_backward(drelu2, saved[\"input_convolve0\"], filters[1])\n",
        "\n",
        "  return dconv1, grads"
      ],
      "metadata": {
        "id": "cWvAzAVmR4I-"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FUNZIONI DI TEST"
      ],
      "metadata": {
        "id": "nzCqumJ-6xNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FORWARD\n",
        "def forward_pass(input_img, target_img, filters, class_weights, n_classes):\n",
        "  print(\"Input immagine:\", input_img.shape)\n",
        "\n",
        "  encoded_img, skip_connections, saved_encoder = encoder(input_img, filters)\n",
        "  print(\"Output dell'encoder:\", encoded_img.shape)\n",
        "\n",
        "  bottleneck_img = bottleneck(encoded_img, filters)\n",
        "  print(\"Output del bottleneck:\", bottleneck_img.shape)\n",
        "\n",
        "  decoded_img, saved_decoder = decoder(bottleneck_img, skip_connections, filters)\n",
        "  print(\"Output del decoder:\", decoded_img.shape)\n",
        "\n",
        "  in_channels = decoded_img.shape[-1]\n",
        "  final_filters = np.random.rand(1, 1, in_channels, n_classes)\n",
        "  final_output = final_convolve_1x1(decoded_img, final_filters)\n",
        "  print(\"Output finale dopo convoluzione 1x1:\", final_output.shape)\n",
        "\n",
        "  loss = weighted_cross_entropy_loss(target_img, final_output, class_weights)\n",
        "  print(\"Loss:\", loss)\n",
        "\n",
        "  return final_output, loss"
      ],
      "metadata": {
        "id": "tZnLgroR64P7"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BACKWARD\n",
        "\n"
      ],
      "metadata": {
        "id": "3HRFDgPAB9m0"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test con immagini e filtri random\n",
        "\n",
        "batch_size = 10\n",
        "img_height, img_width = 176, 208\n",
        "n_classes = 4\n",
        "class_weights = np.random.rand(n_classes)\n",
        "\n",
        "\n",
        "imgs = np.random.rand(batch_size, img_height, img_width, 1)\n",
        "targets = np.random.randint(0, n_classes, size=(batch_size, img_height, img_width))\n",
        "\n",
        "filters = np.random.rand(batch_size,3, 3)\n",
        "filters = np.array(filters)\n",
        "\n",
        "output, loss = forward_pass(imgs, targets, filters, class_weights, n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6-2Zi_j9diQ",
        "outputId": "b770b85b-e8f4-4e14-83e6-4f435b3f1220"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input immagine: (10, 176, 208, 1)\n",
            "Output dell'encoder: (10, 88, 104, 1)\n",
            "Output del bottleneck: (10, 88, 104, 1)\n",
            "Output del decoder: (10, 176, 208, 2)\n",
            "Output finale dopo convoluzione 1x1: (10, 176, 208, 4)\n",
            "Loss: -135238.9005660288\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zYlWqrb12XR7",
        "Rw5x_fnyUQ8C",
        "C9AERDTXVDwq",
        "EugS4zP8UZOx",
        "_Rfpv_EYWCyy",
        "qPRfrEDMUuyX",
        "yYgJfDhoU6ty",
        "ssHjpwQzVR4Z",
        "qARsq0e1VY2G",
        "UbCis-nkVnkW",
        "X5gybPbdVyLp",
        "a35-Kx8hW5nZ",
        "nfrSfH4qTnzX",
        "fKxsDCiUR2xr",
        "FMqUwh4sQ3tC",
        "OwwytHfHCMcM",
        "HwG_DvRzB47D",
        "HhLdmFhOBvEi"
      ],
      "authorship_tag": "ABX9TyOlukHFpnxlVBQztygBeWTR"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}